{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2개의 RNN(recurrent neural networks)s로 이루어져 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Encoder maps a variable-length source sequence(input) to a fixed-length vector\n",
    "* Decoder maps the vector representation back to a variable-length target sequence(output)\n",
    "* Two RNNs are trained jointly to maximize the conditional probability of the target sequence given a source sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# With Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the vanilla model, each input has to be encoded into a fixed-size state vector, as that is the only thing passed to the decoder.\n",
    "* Attention mechanism that gives decoder direct access to the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucketing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avoid too much padding that leads to extraneous computation\n",
    "* Group sequences of similar lengths into the same buckets\n",
    "* Create a separate subgraph for each bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1.0 에 이런게 있다고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.contrib.training.bucket_by_sequence_length(max_length,examples, batch_size, bucket_boundaries, capacity=2 * batch_size, dynamic_pad=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Use bucket_by_sequence_length with the argument dynamic_pad=True to receive minibatches of similarly sized sequences for efficient training via dynamic_rnn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampled Softmax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avoid the growing complexity of computing the normalization constant\n",
    "* Approximate the negative term of the gradient, by importance sampling with a small number of samples\n",
    "* At each step, update only the vectors associated with the correct word w and with the sampled words in V'\n",
    "* Once training is over, use the full target vocabulary to compute the output probability of each target word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if config.NUM_SAMPLES > 0 and config.NUM_SAMPLES < config.DEC_VOCAB:\n",
    "    weight = tf.get_variable('proj_w', [config.HIDDEN_SIZE, config.DEC_VOCAB])\n",
    "    bias = tf.get_variable('proj_b', [config.DEC_VOCAB])\n",
    "    self.output_projection = (w, b)\n",
    "    \n",
    "def sampled_loss(inputs, labels):\n",
    "    labels = tf.reshape(labels, [-1, 1])\n",
    "    return tf.nn.sampled_softmax_loss(tf.transpose(weight), bias, inputs, labels,\n",
    "                 config.NUM_SAMPLES, config.DEC_VOCAB)\n",
    "self.softmax_loss_function = sampled_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제 Predict할 때는 full softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generally an underestimate of the full softmax loss\n",
    "* At inference time, compute the full softmax using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.nn.softmax(tf.matmul(inputs, tf.transpose(weight)) + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq in tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, states = basic_rnn_seq2seq(encoder_inputs, \n",
    "                                    decoder_inputs, \n",
    "                                    cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder_inputs: a list of tensors representing inputs to the encoder <br>\n",
    "decoder_inputs: a list of tensors representing inputs to the decoder <br>\n",
    "cell: single or multiple layer cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputs: a list of decoder_size tensors, each of dimension 1 x DECODE_VOCAB corresponding to the probability distribution at each time-step<br>\n",
    "states: a list of decoder_size tensors, each corresponds to the internal state of the decoder at every time-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 근데 이 밑에 2개는 1.0에서 legacy가 되었네 ㅠ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, states = embedding_rnn_seq2seq(encoder_inputs,\n",
    "                                         decoder_inputs,\n",
    "                                         cell,\n",
    "                                         num_encoder_symbols,\n",
    "                                         num_decoder_symbols,\n",
    "                                         embedding_size,\n",
    "                                         output_projection=None,\n",
    "                                         feed_previous=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시퀀스 모델에 인풋과 아웃풋을 임베딩된 형태로 넘겨주기 위해선,input과 output의 심볼(토큰셋)의 수를 명시해줘야 한다. <br>\n",
    "Output_projection: tuple of project weight and bias if use sampled softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, states = embedding_attention_seq2seq(encoder_inputs,\n",
    "                                             decoder_inputs,\n",
    "                                             cell,\n",
    "                                            num_encoder_symbols,\n",
    "                                            num_decoder_symbols,\n",
    "                                            num_heads=1,\n",
    "                                            output_projection=None,\n",
    "                                            feed_previous=False,\n",
    "                                             initial_state_attention=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper for seq2seq with buckets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, losses = model_with_buckets(encoder_inputs,\n",
    "                                     decoder_inputs,\n",
    "                                     targets,\n",
    "                                     weights,\n",
    "                                     buckets,\n",
    "                                     seq2seq,\n",
    "                                     softmax_loss_function=None,\n",
    "                                     per_example_loss=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
