{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Readers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ops that return different values every time you call them\n",
    "<strong>(Think Python’s generator)</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tf.TextLineReader :Outputs the lines of a file delimited by newlines (E.g. text files, CSV files)\n",
    "\n",
    "* tf.FixedLengthRecordReader :Outputs the entire file when all files have same fixed lengths\n",
    "   (E.g. each MNIST file has 28 x 28 pixels, CIFAR-10 32 x 32 x 3)\n",
    "* tf.WholeFileReader : Outputs the entire file content\n",
    "\n",
    "* tf.TFRecordReader : Reads samples from TensorFlow’s own binary format (TFRecord)\n",
    "* tf.ReaderBase : To allow you to create your own readers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in files from queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filename_queue = tf.train.string_input_producer([\"file0.csv\", \"file1.csv\"]) <br>\n",
    "reader = tf.TextLineReader() <br>\n",
    "key, value = reader.read(filename_queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.FIFOQueue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = tf.FIFOQueue(3, \"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* capacity : 큐의 크기(integer)\n",
    "* dtypes : 데이터 타입\n",
    "* shapes(Optional) : TensorShape\n",
    "* names(Optional)\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = q.enqueue_many(([1.,2.,3.],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(q.dequeue()))\n",
    "    print(sess.run(q.dequeue()))\n",
    "    print(sess.run(q.dequeue()))\n",
    "    sess.run(q.enqueue([5]))\n",
    "    print(sess.run(q.dequeue()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threads & Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "큐들을 관리하기 위해서 tf.train.Coordinator() 와 tf.train.start_queue_runners를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV 파일 읽어오는 예제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/heart.csv'\n",
    "BATCH_SIZE = 3\n",
    "N_FEATURES = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(filenames):\n",
    "    \"\"\" filenames is the list of files you want to read from. \n",
    "    In this case, it contains only heart.csv\n",
    "    \"\"\"\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "    reader = tf.TextLineReader(skip_header_lines=1) # 파일의 첫째줄 스킵\n",
    "    _, value = reader.read(filename_queue)\n",
    "\n",
    "    # record_defaults are the default values in case some of our columns are empty\n",
    "    # This is also to tell tensorflow the format of our data (the type of the decode result)\n",
    "    # for this dataset, out of 9 feature columns, \n",
    "    # 8 of them are floats (some are integers, but to make our features homogenous, \n",
    "    # we consider them floats), and 1 is string (at position 5)\n",
    "    # the last column corresponds to the lable is an integer\n",
    "    \n",
    "    # null값이 있을 수도 있어서 디폴트 레코드를 만든다!?\n",
    "    # value를 읽어오되, null 값이면 디폴트 값을 넣도록\n",
    "    record_defaults = [[1.0] for _ in range(N_FEATURES)] \n",
    "    record_defaults[4] = ['']\n",
    "    record_defaults.append([1])\n",
    "\n",
    "    # read in the 10 rows of data\n",
    "    content = tf.decode_csv(value, record_defaults=record_defaults) \n",
    "    \n",
    "    # 5번째 컬럼을 존재/부재 여부의 이진변수화 시킨다?!\n",
    "    # convert the 5th column (present/absent) to the binary value 0 and 1\n",
    "    condition = tf.equal(content[4], tf.constant('Present'))\n",
    "    content[4] = tf.where(condition, tf.constant(1.0), tf.constant(0.0))\n",
    "\n",
    "    # 각 컬럼이 텐서로 반환되기 때문에 instances로 만든다\n",
    "    # column1 + column2 + ... columnN\n",
    "    features = tf.stack(content[:N_FEATURES])\n",
    "    \n",
    "    \n",
    "    # 레이블 컬럼\n",
    "    # assign the last column to label\n",
    "    label = content[-1]\n",
    "\n",
    "\n",
    "    # 디큐 후 남아 있는 큐 elements의 수(충분히 섞인다는 것을)\n",
    "    # 보장하기 위해서\n",
    "    # 보통 BATCH_SIZE의 10배 정도면 충분하다\n",
    "    min_after_dequeue = 10 * BATCH_SIZE\n",
    "\n",
    "    # 큐의 맥시멈 capacity\n",
    "    capacity = 20 * BATCH_SIZE\n",
    "\n",
    "    # shuffle the data to generate BATCH_SIZE sample pairs\n",
    "    data_batch, label_batch = tf.train.shuffle_batch([features, label], batch_size=BATCH_SIZE, \n",
    "                                        capacity=capacity, min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "    return data_batch, label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.train.string_input_producer(string_tensor, num_epochs=None, shuffle=True, seed=None, capacity=32, shared_name=None, name=None, cancel_op=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output strings (e.g. filenames) to a queue for an input pipeline. (파일 네임의 스트링 리스트를 넣으면 된당?) <br>\n",
    "아! 여러개의 파일을 큐로 만들어 넣고 리더가 하나씩 열어보면서\n",
    "다 불러올 수 있도록 하는 거인듯!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class tf.TextLineReader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Reader that outputs the lines of a file delimited by newlines. (줄 단위로 읽어온다)\n",
    "E.g. text files, CSV files\n",
    "\n",
    "Newlines are stripped from the output. See ReaderBase for supported methods.\n",
    "<br>\n",
    "<br>\n",
    "<strong>read(queue, name=None)</strong><br>\n",
    "Returns the next record (key,value pair) produced by a reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.decode_csv(records, record_defaults, field_delim=None, name=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert CSV records to tensors. Each column maps to one tensor. (각 컬럼이 tensor로 매핑된다?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* records: A Tensor of type string. Each string is a record/row in the csv and all records should have the same format.\n",
    "* record_defaults: A list of Tensor objects with types from: float32, int32, int64, string. One tensor per column of the input record, with either a scalar default value for that column or empty if the column is required.\n",
    "* field_delim: An optional string. Defaults to \",\". delimiter to separate fields in a record.\n",
    "* name: A name for the operation (optional)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.stack(values, axis=0, name='stack') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacks a list of rank-R tensors into one rank-(R+1) tensor. (np.vstack과 유사)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.train.shuffle_batch(tensors, batch_size, capacity, min_after_dequeue, num_threads=1, seed=None, enqueue_many=False, shapes=None, allow_smaller_final_batch=False, shared_name=None, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates batches by randomly shuffling tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Creates batches of 32 images and 32 labels</strong>\n",
    "<br>\n",
    "image_batch, label_batch = tf.train.shuffle_batch(<br>\n",
    "      [single_image, single_label],<br>\n",
    "      batch_size=32,<br>\n",
    "      num_threads=4,<br>\n",
    "      capacity=50000,<br>\n",
    "      min_after_dequeue=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_batches(data_batch, label_batch):\n",
    "    with tf.Session() as sess:\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        for _ in range(10): # generate 10 batches\n",
    "            features, labels = sess.run([data_batch, label_batch])\n",
    "            print(features)\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 114.            0.            3.82999992   19.39999962    1.           49.\n",
      "    24.86000061    2.49000001   29.        ]\n",
      " [ 124.           14.            6.23000002   35.95999908    1.           45.\n",
      "    30.09000015    0.           59.        ]\n",
      " [ 142.           18.20000076    4.34000015   24.37999916    0.           61.\n",
      "    26.19000053    0.           50.        ]]\n",
      "[[ 132.            7.9000001     2.8499999    26.5           1.           51.\n",
      "    26.15999985   25.70999908   44.        ]\n",
      " [ 206.            6.            2.95000005   32.27000046    0.           72.\n",
      "    26.80999947   56.06000137   60.        ]\n",
      " [ 117.            1.52999997    2.44000006   28.95000076    1.           35.\n",
      "    25.88999939   30.03000069   46.        ]]\n",
      "[[ 134.           14.10000038    4.44000006   22.38999939    1.           65.\n",
      "    23.09000015    0.           40.        ]\n",
      " [ 144.            4.09000015    5.55000019   31.39999962    1.           60.\n",
      "    29.43000031    5.55000019   56.        ]\n",
      " [ 120.            7.5          15.32999992   22.            0.           60.\n",
      "    25.30999947   34.49000168   49.        ]]\n",
      "[[ 132.            0.            1.87         17.20999908    0.           49.\n",
      "    23.62999916    0.97000003   15.        ]\n",
      " [ 132.            0.            5.80000019   30.95999908    1.           69.\n",
      "    30.11000061    0.           53.        ]\n",
      " [ 136.           11.19999981    5.80999994   31.85000038    1.           75.\n",
      "    27.68000031   22.94000053   58.        ]]\n",
      "[[ 170.            7.5           6.40999985   38.02999878    1.           51.\n",
      "    31.98999977   24.26000023   58.        ]\n",
      " [ 145.            9.10000038    5.23999977   27.54999924    0.           59.\n",
      "    20.95999908   21.60000038   61.        ]\n",
      " [ 118.            6.            9.64999962   33.90999985    0.           60.\n",
      "    38.79999924    0.           48.        ]]\n",
      "[[ 142.            4.05000019    3.38000011   16.20000076    0.           59.\n",
      "    20.80999947    2.61999989   38.        ]\n",
      " [ 112.            9.64999962    2.28999996   17.20000076    1.           54.\n",
      "    23.53000069    0.68000001   53.        ]\n",
      " [ 138.            0.60000002    3.80999994   28.65999985    0.           54.\n",
      "    28.70000076    1.46000004   58.        ]]\n",
      "[[ 118.            0.28          5.80000019   33.70000076    1.           60.\n",
      "    30.97999954    0.           41.        ]\n",
      " [ 148.            5.5           7.0999999    25.30999947    0.           56.\n",
      "    29.84000015    3.5999999    48.        ]\n",
      " [ 106.            1.61000001    1.74000001   12.31999969    0.           74.\n",
      "    20.92000008   13.36999989   20.        ]]\n",
      "[[ 160.           12.            5.73000002   23.11000061    1.           49.\n",
      "    25.29999924   97.19999695   52.        ]\n",
      " [ 126.            3.79999995    3.88000011   31.79000092    0.           57.\n",
      "    30.53000069    0.           30.        ]\n",
      " [ 152.            0.89999998    9.11999989   30.22999954    0.           56.\n",
      "    28.63999939    0.37         42.        ]]\n",
      "[[ 112.            0.41          1.88         10.28999996    0.           39.\n",
      "    22.07999992   20.97999954   27.        ]\n",
      " [ 124.            4.82000017    3.24000001   21.10000038    1.           48.\n",
      "    28.48999977    8.42000008   30.        ]\n",
      " [ 128.            4.6500001     3.30999994   22.73999977    0.           62.\n",
      "    22.95000076    0.50999999   48.        ]]\n",
      "[[ 136.            7.36000013    2.19000006   28.11000061    1.           61.\n",
      "    25.           61.70999908   54.        ]\n",
      " [ 150.            0.30000001    6.38000011   33.99000168    1.           62.\n",
      "    24.63999939    0.           50.        ]\n",
      " [ 122.            6.5999999     5.57999992   35.95000076    1.           53.\n",
      "    28.06999969   12.55000019   59.        ]]\n"
     ]
    }
   ],
   "source": [
    "data_batch, label_batch = batch_generator([DATA_PATH])\n",
    "generate_batches(data_batch, label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class tf.train.Coordinator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coordinator for threads.\n",
    "\n",
    "This class implements a simple mechanism to coordinate the termination of a set of threads. <br><br>\n",
    "쓰레드를 계속 감시한다? 쓰레드를 돌리고 멈추는 것을 관리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Create a coordinator.` <br>\n",
    "coord = Coordinator() <br>\n",
    "`Start a number of threads, passing the coordinator to each of them.`<br>\n",
    "...start thread 1...(coord, ...)<br>\n",
    "...start thread N...(coord, ...)<br>\n",
    "`Wait for all the threads to terminate.`<br>\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.train.start_queue_runners(sess=None, coord=None, daemon=True, start=True, collection=tf.GraphKeys.QUEUE_RUNNERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starts all queue runners collected in the graph.\n",
    "\n",
    "This is a companion method to add_queue_runner(). It just starts threads for all queue runners collected in the graph. It returns the list of all threads.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 data가 있는 storage와 worker가 각각 다른 곳에 있다면 즉, client를 한번 거쳐야 한다면 feed_dict에서 병목 현상이 일어난다?! <br>\n",
    "<strong>Data Readers</strong>를 이용하면 client를 거치지 않고 바로 storage가 worker의 process로 갈 수 있도록 해준다.(generator) <br>\n",
    "아직 뭐가 장점인지 와닿지는 않지만 속도 상의 이점이 있겠지?! <br>\n",
    "cf. 그래프 위에 있는 큐들은 단독으로 sess.run은 안되고 queue_runner를 이용해서 thread 위에서 실제로 불러올 수 있당? 이 threads를 관리해주는 것은 Coordinator이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
